{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6 Code Explanation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import random\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import community as community_louvain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 0: Preparing the Graph\n",
    "\n",
    "We start by loading the graph data from CSV files, create an undirected, unweighted graph, and focus on its largest connected component.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the graph data from CSV files\n",
    "edges_filename = \"edges.csv\"\n",
    "nodes_filename = \"nodes.csv\"\n",
    "\n",
    "df_edges = pd.read_csv(edges_filename)\n",
    "df_nodes = pd.read_csv(nodes_filename)\n",
    "\n",
    "# Create the graph using the edges CSV\n",
    "G = nx.from_pandas_edgelist(df_edges, '# source', ' target')\n",
    "\n",
    "# Ensure the graph is undirected and unweighted\n",
    "G = nx.to_undirected(G)\n",
    "\n",
    "# Remove self-loops if necessary\n",
    "if nx.is_frozen(G):\n",
    "    G = nx.Graph(G)  # Unfreeze if frozen\n",
    "G.remove_edges_from(nx.selfloop_edges(G))\n",
    "\n",
    "# Keep only the largest connected component\n",
    "largest_cc = max(nx.connected_components(G), key=len)\n",
    "G = G.subgraph(largest_cc).copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 1: Implementing Community Detection Techniques\n",
    "\n",
    "We implement three different community detection techniques: Bridge Removal Method, Modularity Optimization, and Label Propagation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Bridge Removal Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bridge_removal_partition(G):\n",
    "    # Create a copy of the graph to work with\n",
    "    G_no_bridges = G.copy()\n",
    "\n",
    "    # Identify all bridges in the graph\n",
    "    bridges = list(nx.bridges(G_no_bridges))\n",
    "\n",
    "    # Remove these bridges from the graph\n",
    "    G_no_bridges.remove_edges_from(bridges)\n",
    "\n",
    "    # Identify the connected components in the graph after bridge removal\n",
    "    components = [G_no_bridges.subgraph(c).copy() for c in nx.connected_components(G_no_bridges)]\n",
    "\n",
    "    # Initialize lists to store modularity scores and community partitions\n",
    "    modularity_scores = []\n",
    "    community_partitions = []\n",
    "\n",
    "    # Iterate over each component formed after removing bridges\n",
    "    for comp in components:\n",
    "        # Get the nodes in the current component\n",
    "        community = list(comp.nodes)\n",
    "\n",
    "        # Identify all other nodes in the graph not in the current component\n",
    "        other_nodes = set(G.nodes()) - set(community)\n",
    "\n",
    "        # Create a partition dictionary where nodes in the community are marked '0' and others '1'\n",
    "        partition = {node: 0 for node in community}\n",
    "        partition.update({node: 1 for node in other_nodes})\n",
    "\n",
    "        # Convert the partition dictionary to a format suitable for modularity calculation\n",
    "        reverse_partition = {}\n",
    "        for node, community_id in partition.items():\n",
    "            reverse_partition.setdefault(community_id, set()).add(node)\n",
    "\n",
    "        # Get the communities as a list of sets of nodes\n",
    "        communities = list(reverse_partition.values())\n",
    "\n",
    "        # Store the partition\n",
    "        community_partitions.append(partition)\n",
    "\n",
    "        # Calculate and store the modularity score for this partition\n",
    "        modularity_score = nx.community.modularity(G, communities)\n",
    "        modularity_scores.append(modularity_score)\n",
    "\n",
    "    # Identify the partition with the highest modularity score\n",
    "    max_modularity_index = modularity_scores.index(max(modularity_scores))\n",
    "\n",
    "    # Return the partition with the highest modularity\n",
    "    return community_partitions[max_modularity_index]\n",
    "\n",
    "  \n",
    "# Apply Bridge Removal\n",
    "start_time = time.time()\n",
    "best_partition_bridge_removal = bridge_removal_partition(G)\n",
    "bridge_time = time.time() - start_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Modularity Optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "partition_modularity_optimization = community_louvain.best_partition(G)\n",
    "modularity_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C) Label Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "communities_label_prop = list(nx.community.label_propagation_communities(G))\n",
    "label_prop_time = time.time() - start_time\n",
    "partition_label_prop = {node: i for i, comm in enumerate(communities_label_prop) for node in comm}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 2: Analysis and Comparison of Results\n",
    "\n",
    "We collect the results from each method, including the number of clusters, cluster sizes, and modularity scores, and then compare these metrics across methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Method  Number of Clusters Cluster Size Distribution  \\\n",
      "0           Bridge Removal                   2                   [1, 81]   \n",
      "1  Modularity Optimization                   6     [17, 32, 17, 6, 7, 3]   \n",
      "2        Label Propagation                   2                   [5, 77]   \n",
      "\n",
      "   Computational Time (s)  Modularity  \n",
      "0                0.016789   -0.000019  \n",
      "1                0.000000    0.427583  \n",
      "2                0.007007    0.083829  \n"
     ]
    }
   ],
   "source": [
    "# Collecting results from each method\n",
    "def collect_results(G, partition):\n",
    "    # Convert the partition dictionary into a structure of sets, where each set represents a community\n",
    "    reverse_partition = {}\n",
    "    for node, community_id in partition.items():\n",
    "        # For each node, add it to the set corresponding to its community\n",
    "        reverse_partition.setdefault(community_id, set()).add(node)\n",
    "    \n",
    "    # Convert the sets of communities into a list\n",
    "    communities = list(reverse_partition.values())\n",
    "\n",
    "    # Count the number of communities (clusters) in the partition\n",
    "    num_clusters = len(communities)\n",
    "\n",
    "    # Calculate the size (number of nodes) of each community\n",
    "    cluster_sizes = [len(c) for c in communities]\n",
    "\n",
    "    # Compute the modularity of the partition, a measure of the strength of the division of a network into communities\n",
    "    modularity = nx.community.modularity(G, communities)\n",
    "\n",
    "    # Return the number of clusters, the size of each cluster, and the modularity score\n",
    "    return num_clusters, cluster_sizes, modularity\n",
    "\n",
    "bridge_results = collect_results(G, best_partition_bridge_removal)\n",
    "modularity_results = collect_results(G, partition_modularity_optimization)\n",
    "label_prop_results = collect_results(G, partition_label_prop)\n",
    "\n",
    "# Creating a DataFrame for comparison\n",
    "results_df = pd.DataFrame({\n",
    "    'Method': ['Bridge Removal', 'Modularity Optimization', 'Label Propagation'],\n",
    "    'Number of Clusters': [bridge_results[0], modularity_results[0], label_prop_results[0]],\n",
    "    'Cluster Size Distribution': [bridge_results[1], modularity_results[1], label_prop_results[1]],\n",
    "    'Computational Time (s)': [bridge_time, modularity_time, label_prop_time],\n",
    "    'Modularity': [bridge_results[2], modularity_results[2], label_prop_results[2]]\n",
    "})\n",
    "\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 3: Analysis of Community Detection Methods\n",
    "\n",
    "#### **Bridge Removal Method:**\n",
    "- **Number of Clusters:** This method resulted in only 2 clusters, with a highly uneven distribution: a very small cluster (just 1 node) and a much larger one (81 nodes). This outcome implies that the removal of bridges in the network predominantly isolates a small subset of nodes, while the rest of the network remains largely interconnected.\n",
    "- **Modularity:** The modularity score is extremely low, hovering around zero. Such a low score suggests that the community division offered by this method is almost arbitrary and does not reveal any significant structure within the network. It may oversimplify the community structure, failing to capture the complexity of the network.\n",
    "\n",
    "#### **Modularity Optimization (Louvain Method):**\n",
    "- **Number of Clusters:** This approach identified 6 clusters, displaying a more balanced size distribution ranging from 3 to 32 nodes. The discovery of a higher number of clusters with more varied sizes indicates that the network possesses a more intricate community structure.\n",
    "- **Modularity:** The modularity score is considerably high at approximately 0.428. A high modularity score like this one indicates that the Louvain method successfully identified communities where nodes are more densely connected internally than with the rest of the network. This suggests that it is the most effective method in capturing the true community structure of your network.\n",
    "\n",
    "#### **Label Propagation:**\n",
    "- **Number of Clusters:** Similar to the Bridge Removal method, Label Propagation found 2 clusters but with a different distribution (5 and 77 nodes). This method, known for its simplicity and speed, appears to capture some aspects of the network's community structure but might not be as nuanced or accurate in complex networks.\n",
    "- **Modularity:** The modularity score here, while better than that of the Bridge Removal method, is considerably lower than that achieved by the Modularity Optimization method. This indicates that while Label Propagation does recognize some community structure, it is not as effective or detailed as the Modularity Optimization approach.\n",
    "\n",
    "### Summary and Conclusion\n",
    "\n",
    "- **Modularity Optimization** (Louvain Method) emerges as the most effective method for this particular network. Its ability to identify a balanced and nuanced community structure, supported by a high modularity score, suggests that it captures the network's community dynamics most accurately.\n",
    "- **Bridge Removal Method**, despite its conceptual simplicity, appears to be the least effective for this network. Its almost zero modularity score and binary community split indicate an oversimplification of the network's community structure.\n",
    "- **Label Propagation** offers a middle ground with its simplicity and speed, but it does not capture the community structure as effectively as the Modularity Optimization method, particularly in networks with more complex structures.\n",
    "\n",
    "In summary, the **Modularity Optimization** method appears to be the most effective for your network, given its higher modularity score and a more balanced community size distribution. The Bridge Removal method does not seem effective for your network, as indicated by its very low modularity. Label Propagation provides a middle ground, being faster but less accurate than Modularity Optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 4: Visualization Hints for Gephi\n",
    "\n",
    "After choosing the best partition based on our analysis, we prepare the data for visualization in Gephi by exporting the network with community data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the best partition based on your analysis\n",
    "best_partition = partition_modularity_optimization\n",
    "\n",
    "# Add community information to nodes for export\n",
    "for node, comm_id in best_partition.items():\n",
    "    G.nodes[node]['community'] = comm_id\n",
    "\n",
    "# Export the graph with community data to GEXF for Gephi\n",
    "nx.write_gexf(G, \"network_with_communities.gexf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
